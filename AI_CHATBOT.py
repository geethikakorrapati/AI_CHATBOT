# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u_sK-fvUBRGRBW_tiJAu1KxZJfGCmyvk
"""

!pip install --upgrade pip
!pip install transformers accelerate gradio

import torch
print("GPU available:", torch.cuda.is_available())

from huggingface_hub import login
login(token="")

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

MODEL_NAME = "gpt2"   # change to any model repo you want

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)

model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    device_map="auto",
    torch_dtype="auto",
    trust_remote_code=True
)

text_pipe = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=128,
    temperature=0.7,
    top_p=0.9
)

result = text_pipe("Hello! Can you explain what AI is?", do_sample=True)
print(result[0]["generated_text"])

!pip install --upgrade googlesearch-python newspaper3k lxml_html_clean

from googlesearch import search
from newspaper import Article
import logging

def web_search(query, max_results=5, snippet_chars=300):
    """
    Run a Google search for `query`, return up to `max_results` results.
    Each result is parsed with newspaper3k.
    Returns: list of dicts [{title, href, body}]
    """
    results = []
    for url in search(query, num_results=max_results, lang="en"):
        try:
            art = Article(url)
            art.download()
            art.parse()
            text = art.text.replace("\n", " ").strip()
            snippet = text[:snippet_chars] + ("‚Ä¶" if len(text) > snippet_chars else "")
            results.append({
                "title": art.title or url,
                "href": url,
                "body": snippet
            })
        except Exception as e:
            logging.warning(f"Failed to parse {url}: {e}")
        if len(results) >= max_results:
            break
    return results
results = web_search("latest AI news", max_results=3)

for i, r in enumerate(results, start=1):
    print(f"\nResult {i}:")
    print("Title :", r["title"])
    print("Link  :", r["href"])
    print("Body  :", r["body"])

def answer_with_citations(user_query):
    hits = web_search(user_query, max_results=10)

    prompt_parts = [
        "You are an AI assistant. Use the following search results to answer the question.\n"
        "Explain clearly, list points if needed, and cite each source by its link.\n"
    ]

    for idx, hit in enumerate(hits, start=1):
        title = hit.get("title", "").strip()
        body  = hit.get("body", "").strip()
        url   = hit.get("href", hit.get("url", "")).strip()
        prompt_parts.append(f"[{idx}] {title}\n{body}\nURL: {url}\n")

    prompt_parts.append(f"Question: {user_query}\nAnswer:")
    prompt = "\n".join(prompt_parts)

    generated = llama_pipe(prompt, max_new_tokens=512, temperature=0.7)[0]["generated_text"]
    answer = generated[len(prompt):].strip()
    return answer

import gradio as gr

def chat_fn(user_message, history):
    history = history + [(user_message, None)]
    bot_reply = answer_with_citations(user_message)
    history[-1] = (user_message, bot_reply)
    return history, history, ""

css = """
.gradio-container { display: flex; justify-content: center; padding: 2rem; }
.chat-box { width: 100%; max-width: 700px; }
.chatbot .message.user {
  background-color: #007AFF;
  color: white;
  border-radius: 16px 16px 0 16px;
  padding: 8px 12px;
  margin: 4px 0;
  align-self: flex-end;
  max-width: 80%;
}
.chatbot .message.bot {
  background-color: #FFA500;
  color: #111;
  border-radius: 16px 16px 16px 0;
  padding: 8px 12px;
  margin: 4px 0;
  align-self: flex-start;
  max-width: 80%;
}
input[type="text"] {
  border-radius: 20px;
  padding: 10px 16px;
  border: 1px solid #CCC;
}
"""

with gr.Blocks(css=css, title="üì° LLaMA 3.2 3B Web-Search Agent") as demo:
    gr.Markdown("## Ask anything and get cited answers")
    with gr.Group(elem_classes="chat-box"):
        chatbot = gr.Chatbot(elem_classes="chatbot", height=500)
        state   = gr.State([])
        user_input = gr.Textbox(
            placeholder="Type your question and hit enter",
            show_label=False
        )
        clear_btn = gr.Button("üóëÔ∏è Clear Chat")

    user_input.submit(
        fn=chat_fn,
        inputs=[user_input, state],
        outputs=[chatbot, state, user_input]
    )

    clear_btn.click(
        fn=lambda: ([], [], ""),
        inputs=None,
        outputs=[chatbot, state, user_input]
    )

demo.launch(share=True)